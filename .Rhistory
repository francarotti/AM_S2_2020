library(ggplot2)
library(maptools)
require(doBy)
install.packages("mnormt")
require(mnormt)
require(betareg)
install.packages("betareg")
install.packages("fields")
install.packages("geoR")
install.packages("rstan")
install.packages(c("CARBayes", "geoR"))
install.packages("mcmc")
install.packages(c("CARBayes", "geoR"))
library(mcmc)
install.packages(c("MCMCpack"))
install.packages("~/Downloads/mcmc_0.9-5.tar.gz", repos=NULL, type="source")
install.packages(c("MCMCpack"))
version
install.packages(c("geoR"))
install.packages("RandomFieldsUtils")
install.packages(c("geoR"))
install.packages(c("ape", "astsa", "backports", "BB", "bibtex", "bigmemory", "bit", "blob", "broom", "callr", "checkmate", "chron", "circlize", "classInt", "cli", "clipr", "coda", "corrplot", "covr", "crosstalk", "cubature", "curl", "data.table", "DBI", "dbplyr", "deldir", "dendextend", "devtools", "digest", "doParallel", "dplyr", "dtplyr", "e1071", "ellipsis", "evaluate", "fansi", "farver", "forcats", "foreach", "forecast", "formatR", "fracdiff", "fs", "gamlss", "gamlss.add", "gamlss.dist", "gdalUtils", "gdtools", "gender", "geometry", "ggforce", "ggplot2", "ggraph", "ggrepel", "gh", "git2r", "GlobalOptions", "glue", "goftest", "gstat", "gtools", "gutenbergr", "h2o", "haven", "hexbin", "Hmisc", "hms", "htmlTable", "htmltools", "htmlwidgets", "httpuv", "httr", "igraph", "intervals", "iterators", "jomo", "jpeg", "jsonlite", "kernlab", "KFAS", "knitr", "later", "leafem", "leaflet", "leafpop", "leaps", "lme4", "lpSolve", "lubridate", "manipulateWidget", "mapproj", "maptools", "mapview", "markdown", "matrixStats", "maxLik", "mclust", "mcmc", "mice", "miceadds", "microbenchmark", "mime", "miscTools", "modelr", "modeltools", "multicool", "network", "nloptr", "NMF", "np", "numDeriv", "nycflights13", "OpenImageR", "openNLP", "openNLPdata", "openssl", "ordinal", "pillar", "pinp", "pkgbuild", "pkgconfig", "pkgKitten", "pkgmaker", "plot3D", "plotly", "plyr", "polspline", "portfolio", "prabclus", "pracma", "prettyunits", "processx", "ProjectTemplate", "promises", "ps", "psych", "purrr", "qdap", "qdapTools", "quadprog", "quantmod", "quantreg", "R.methodsS3", "R.oo", "R.utils", "R6", "raster", "Rcpp", "RcppArmadillo", "RcppEigen", "RcppParallel", "RcppProgress", "RCurl", "remotes", "reshape2", "reticulate", "rex", "rgeos", "rgl", "rJava", "RJSONIO", "rlang", "rmarkdown", "RMySQL", "rngtools", "robustbase", "RSpectra", "RSQLite", "rstudioapi", "Rttf2pt1", "rvest", "RWeka", "RWekajars", "satellite", "scales", "selectr", "sf", "shape", "shiny", "slam", "sn", "SnowballC", "spacetime", "spacyr", "spam", "SparseM", "SpatialPack", "spatialreg", "spatstat", "spatstat.data", "spatstat.utils", "spData", "spdep", "statmod", "stopwords", "stringdist", "stringi", "strucchange", "svglite", "sys", "testthat", "tibble", "tidycensus", "tidyr", "tidyselect", "tidytext", "tidyverse", "tigris", "tinytex", "tm", "topicmodels", "trimcluster", "tseries", "TTR", "units", "uroot", "usethis", "uuid", "vctrs", "wavelets", "waveslim", "webshot", "whisker", "widyr", "withr", "xfun", "xlsx", "XML", "xml2", "xts", "yaImpute", "yaml", "zoo"))
library(spdep)
install.packages("sf")
library(sf)
library(spdep)
library(spdep)
library(sf)
library(spdep)
library(spdep)
library(sp)
library(ggplot2)
library(maptools)
require(doBy)
require(mnormt)
require(betareg)
require(fields)
require(geoR)
require(rstan)
install.packages("geoR")
install.packages("CARBayes")
version
install.packages("CARBayes")
install.packages("geoR")
install.packages(/home/rodney/Downloads/RandomFields_3.3.8.tar.gz, repos = NULL, type="source")
install.packages("/home/rodney/Downloads/RandomFields_3.3.8.tar.gz", repos = NULL, type="source")
install.packages("instaR")
library(instaR)
install.packages("RandomFields")
install.packages(c("betareg", "CARBayes", "doBy", "fields", "geoR", "ggplot2", "maptools", "mnormt", "rstan", "sp", "spdep"))
library(CARBayes)
library(spdep)
library(sp)
library(ggplot2)
library(maptools)
require(doBy)
require(mnormt)
require(betareg)
require(fields)
require(geoR)
require(rstan)
rsconnect::setAccountInfo(name='insightdataanalysis',
token='AA9EDC4CB16F170F0586AEFE5D28AA46',
secret='K6Usf4pndxY4MqiU8rQRSZrzSdgNWA6GVRa5JEiF')
install.packages("rsconnect")
rsconnect::setAccountInfo(name='insightdataanalysis',
token='AA9EDC4CB16F170F0586AEFE5D28AA46',
secret='K6Usf4pndxY4MqiU8rQRSZrzSdgNWA6GVRa5JEiF')
library(MASS)
corre<-c(0,0,-0.9,0.9)
# lets first simulate a bivariate normal sample
bivn <- mvrnorm(10000, mu = c(0, 0), Sigma = matrix(c(1, corre[1], corre[1], 1), 2))
# now we do a kernel density estimate
bivn.kde <- kde2d(bivn[,1], bivn[,2], n = 50)
#dev.new(width=20, height=5)
#par(mar=c(0.01,0.01,0.01,0.01))
par(mfrow=c(2,2))
par(mar = c(0, 0, 0, 0))
# now plot your results
persp(bivn.kde, phi = 45, theta = 30, shade = .1,main=paste("correla??o = ",0),col="lightblue",ticktype="detailed",cex.axis=1.3,cex.lab=1.3,cex.main=1.3,xlab="",ylab="",zlab="")
bivn <- mvrnorm(10000, mu = c(0, 0), Sigma = matrix(c(9, corre[2], corre[2], 9), 2))
# now we do a kernel density estimate
bivn.kde <- kde2d(bivn[,1], bivn[,2], n = 50)
# now plot your results
persp(bivn.kde, phi = 45, theta = 30, shade = .1,main=paste("correla??o = ",0, ", vari?ncias = ",9),col="lightblue",ticktype="detailed",cex.axis=1.3,cex.lab=1.3,cex.main=1.3,xlab="",ylab="",zlab="")
bivn <- mvrnorm(10000, mu = c(0, 0), Sigma = matrix(c(1, corre[3], corre[3], 1), 2))
# now we do a kernel density estimate
bivn.kde <- kde2d(bivn[,1], bivn[,2], n = 50)
# now plot your results
persp(bivn.kde, phi = 45, theta = 30, shade = .1,main=paste("correla??o = ",corre[3]),col="lightblue",ticktype="detailed",cex.axis=1.3,cex.lab=1.3,cex.main=1.3,xlab="",ylab="",zlab="")
bivn <- mvrnorm(10000, mu = c(0, 0), Sigma = matrix(c(1, corre[4], corre[4], 1), 2))
# now we do a kernel density estimate
bivn.kde <- kde2d(bivn[,1], bivn[,2], n = 50)
# now plot your results
persp(bivn.kde, phi = 45, theta = 30, shade = .1,main=paste("correla??o = ",corre[4]),col="lightblue",ticktype="detailed",cex.axis=1.3,cex.lab=1.3,cex.main=1.3,xlab="",ylab="",zlab="")
corre<-c(0,0,-0.9,0.9)
#par(mfrow=c(2,2))
# lets first simulate a bivariate normal sample
bivn <- mvrnorm(10000, mu = c(0, 0), Sigma = matrix(c(1, corre[1], corre[1], 1), 2))
# now we do a kernel density estimate
bivn.kde <- kde2d(bivn[,1], bivn[,2], n = 50)
#pdf("E://windows//Unicamp//Disciplinas//2_semestre_2013//Inferencia Bayesiana//Aulas//Inferencia Bayesiana em Modelos Lineares//AllNM.pdf")
resetPar <- function() {
dev.new()
op <- par(no.readonly = TRUE)
dev.off()
op
}
#dev.new(width=20, height=5)
#par(mar=c(0.01,0.01,0.01,0.01))
par(resetPar())
par(mfrow=c(2,2))
#par(mar = c(0, 0, 0, 0))
# now plot your results
contour(bivn.kde,main=paste("correla??o = ",0),cex.axis=1.3,cex.lab=1.3,cex.main=1.3,xlab="",ylab="")
bivn <- mvrnorm(10000, mu = c(0, 0), Sigma = matrix(c(9, corre[2], corre[2], 9), 2))
# now we do a kernel density estimate
bivn.kde <- kde2d(bivn[,1], bivn[,2], n = 50)
# now plot your results
contour(bivn.kde,main=paste("correla??o = ",0),cex.axis=1.3,cex.lab=1.3,cex.main=1.3,xlab="",ylab="")
bivn <- mvrnorm(10000, mu = c(0, 0), Sigma = matrix(c(1, corre[3], corre[3], 1), 2))
# now we do a kernel density estimate
bivn.kde <- kde2d(bivn[,1], bivn[,2], n = 50)
# now plot your results
contour(bivn.kde,main=paste("correla??o = ",corre[3]),cex.axis=1.3,cex.lab=1.3,cex.main=1.3,xlab="",ylab="")
bivn <- mvrnorm(10000, mu = c(0, 0), Sigma = matrix(c(1, corre[4], corre[4], 1), 2))
# now we do a kernel density estimate
bivn.kde <- kde2d(bivn[,1], bivn[,2], n = 50)
# now plot your results
contour(bivn.kde, main=paste("correla??o = ",corre[4]),cex.axis=1.3,cex.lab=1.3,cex.main=1.3,xlab="",ylab="")
library(MASS)
corre<-c(0,0,-0.9,0.9)
corre
# lets first simulate a bivariate normal sample
bivn <- mvrnorm(10000, mu = c(0, 0), Sigma = matrix(c(1, corre[1], corre[1], 1), 2))
dim(bivn)
# now we do a kernel density estimate
bivn.kde <- kde2d(bivn[,1], bivn[,2], n = 50)
bivn.kde
# now plot your results
persp(bivn.kde, phi = 45, theta = 30, shade = .1,main=paste("correla??o = ",0),col="lightblue",ticktype="detailed",cex.axis=1.3,cex.lab=1.3,cex.main=1.3,xlab="",ylab="",zlab="")
?kde2d
# esses são o resultados dos gráficos
persp(bivn.kde, phi = 45, theta = 30, shade = .1,main=paste("correlação = ",0),col="lightblue",ticktype="detailed",cex.axis=1.3,cex.lab=1.3,cex.main=1.3,xlab="",ylab="",zlab="")
bivn <- mvrnorm(10000, mu = c(0, 0), Sigma = matrix(c(9, corre[2], corre[2], 9), 2))
# now we do a kernel density estimate
bivn.kde <- kde2d(bivn[,1], bivn[,2], n = 50)
# now plot your results
persp(bivn.kde, phi = 45, theta = 30, shade = .1,main=paste("correla??o = ",0, ", vari?ncias = ",9),col="lightblue",ticktype="detailed",cex.axis=1.3,cex.lab=1.3,cex.main=1.3,xlab="",ylab="",zlab="")
bivn <- mvrnorm(10000, mu = c(0, 0), Sigma = matrix(c(9, corre[2], corre[2], 9), 2))
# estimação da densidade por núcleo
bivn.kde <- kde2d(bivn[,1], bivn[,2], n = 50)
# gráfico dos resultados
persp(bivn.kde, phi = 45, theta = 30, shade = .1,main=paste("correlação = ",0, ", vari?ncias = ",9),col="lightblue",ticktype="detailed",cex.axis=1.3,cex.lab=1.3,cex.main=1.3,xlab="",ylab="",zlab="")
bivn <- mvrnorm(10000, mu = c(0, 0), Sigma = matrix(c(9, corre[2], corre[2], 9), 2))
# estimação da densidade por núcleo
bivn.kde <- kde2d(bivn[,1], bivn[,2], n = 50)
# gráfico dos resultados
persp(bivn.kde, phi = 45, theta = 30, shade = .1,
main=paste("correlação = ",0, ", variâncias = ",9),col="lightblue",
ticktype="detailed",cex.axis=1.3,cex.lab=1.3,cex.main=1.3,xlab="",
ylab="",zlab="")
corre<-c(0,0,-0.9,0.9)
#par(mfrow=c(2,2))
# lets first simulate a bivariate normal sample
bivn <- mvrnorm(10000, mu = c(0, 0), Sigma = matrix(c(1, corre[1], corre[1], 1), 2))
# now we do a kernel density estimate
bivn.kde <- kde2d(bivn[,1], bivn[,2], n = 50)
#pdf("E://windows//Unicamp//Disciplinas//2_semestre_2013//Inferencia Bayesiana//Aulas//Inferencia Bayesiana em Modelos Lineares//AllNM.pdf")
resetPar <- function() {
dev.new()
op <- par(no.readonly = TRUE)
dev.off()
op
}
#dev.new(width=20, height=5)
#par(mar=c(0.01,0.01,0.01,0.01))
par(resetPar())
par(mfrow=c(2,2))
#par(mar = c(0, 0, 0, 0))
# now plot your results
contour(bivn.kde,main=paste("correla??o = ",0),cex.axis=1.3,cex.lab=1.3,cex.main=1.3,xlab="",ylab="")
# vetor de correlações que usaremos nas densidades
corre<-c(0,0,-0.9,0.9)
#par(mfrow=c(2,2))
# simulando uma amostra da normal bivariada
bivn <- mvrnorm(10000, mu = c(0, 0), Sigma = matrix(c(1, corre[1], corre[1], 1), 2))
# estimação da densidade por núcleo
bivn.kde <- kde2d(bivn[,1], bivn[,2], n = 50)
#pdf("E://windows//Unicamp//Disciplinas//2_semestre_2013//Inferencia Bayesiana//Aulas//Inferencia Bayesiana em Modelos Lineares//AllNM.pdf")
resetPar <- function() {
dev.new()
op <- par(no.readonly = TRUE)
dev.off()
op
}
#dev.new(width=20, height=5)
#par(mar=c(0.01,0.01,0.01,0.01))
par(resetPar())
#dev.new(width=20, height=5)
#par(mar=c(0.01,0.01,0.01,0.01))
par(resetPar())
par(mfrow=c(2,2))
#dev.new(width=20, height=5)
#par(mar=c(0.01,0.01,0.01,0.01))
par(resetPar())
par(mfrow=c(2,2))
#par(mar = c(0, 0, 0, 0))
# now plot your results
contour(bivn.kde,main=paste("correlação = ",0),cex.axis=1.3,cex.lab=1.3,cex.main=1.3,xlab="",ylab="")
#par(mar = c(0, 0, 0, 0))
# now plot your results
contour(bivn.kde,main=paste("correlação = ",0),cex.axis=1.3,cex.lab=1.3,cex.main=1.3,xlab="",ylab="")
#dev.new(width=20, height=5)
#par(mar=c(0.01,0.01,0.01,0.01))
par(resetPar())
#par(mar = c(0, 0, 0, 0))
# now plot your results
contour(bivn.kde,main=paste("correlação = ",0),cex.axis=1.3,cex.lab=1.3,cex.main=1.3,xlab="",ylab="")
# vetor de correlações que usaremos nas densidades
corre<-c(0,0,-0.9,0.9)
#par(mfrow=c(2,2))
# simulando uma amostra da normal bivariada
bivn <- mvrnorm(10000, mu = c(0, 0), Sigma = matrix(c(1, corre[1], corre[1], 1), 2))
# estimação da densidade por núcleo
bivn.kde <- kde2d(bivn[,1], bivn[,2], n = 50)
# função para sair do modo que divide a tela nos gráficos
resetPar <- function() {
dev.new()
op <- par(no.readonly = TRUE)
dev.off()
op
}
#dev.new(width=20, height=5)
#par(mar=c(0.01,0.01,0.01,0.01))
par(resetPar())
par(mfrow=c(2,2))
#par(mar = c(0, 0, 0, 0))
# now plot your results
contour(bivn.kde,main=paste("correlação = ",0),cex.axis=1.3,cex.lab=1.3,cex.main=1.3,xlab="",ylab="")
# função para sair do modo que divide a tela nos gráficos
resetPar <- function() {
dev.new()
op <- par(no.readonly = TRUE)
dev.off()
op
}
# vetor de correlações que usaremos nas densidades
corre<-c(0,0,-0.9,0.9)
#par(mfrow=c(2,2))
# simulando uma amostra da normal bivariada
bivn <- mvrnorm(10000, mu = c(0, 0), Sigma = matrix(c(1, corre[1], corre[1], 1), 2))
# estimação da densidade por núcleo
bivn.kde <- kde2d(bivn[,1], bivn[,2], n = 50)
#dev.new(width=20, height=5)
#par(mar=c(0.01,0.01,0.01,0.01))
par(resetPar())
par(mfrow=c(2,2))
#par(mar = c(0, 0, 0, 0))
# gráfico dos resultados
contour(bivn.kde,main=paste("correlação = ",0),cex.axis=1.3,cex.lab=1.3,cex.main=1.3,xlab="",ylab="")
bivn <- mvrnorm(10000, mu = c(0, 0), Sigma = matrix(c(9, corre[2], corre[2], 9), 2))
# estimação da densidade por núcleo
bivn.kde <- kde2d(bivn[,1], bivn[,2], n = 50)
# gráfico dos resultados
contour(bivn.kde,main=paste("correla??o = ",0),cex.axis=1.3,cex.lab=1.3,
cex.main=1.3,xlab="",ylab="")
bivn <- mvrnorm(10000, mu = c(0, 0), Sigma = matrix(c(1, corre[3], corre[3], 1), 2))
# estimação da densidade por núcleo
bivn.kde <- kde2d(bivn[,1], bivn[,2], n = 50)
# gráfico dos resultados
contour(bivn.kde,main=paste("correla??o = ",corre[3]),cex.axis=1.3,cex.lab=1.3,cex.main=1.3,xlab="",ylab="")
bivn <- mvrnorm(10000, mu = c(0, 0), Sigma = matrix(c(1, corre[4], corre[4], 1), 2))
# estimação da densidade por núcleo
bivn.kde <- kde2d(bivn[,1], bivn[,2], n = 50)
# gráfico dos resultados
contour(bivn.kde, main=paste("correla??o = ",corre[4]),cex.axis=1.3,cex.lab=1.3,cex.main=1.3,xlab="",ylab="")
library(nycflights13)
View(flights)
hist(flights$dep_time)
hist(flights$sched_dep_time)
hist(flights$air_time)
hist(flights$distance)
require(ggplot2)
data("diamonds")
View("diamonds")
View(diamonds)
hist(diamonds$carat)
hist(diamonds$price)
?diamonds
hist(diamonds$x)
hist(diamonds$y)
hist(diamonds$z)
require(tidyverse)
diamonds %>% filter(y<15) %>% hist
class(diamonds)
diamonds %>% select(y) %>% filter(y<15) %>% hist
diamonds %>% select(y) %>% filter(y<15) %>% summarise(n=mean)
diamonds %>% select(y) %>% filter(y<15) %>% with(hist(y))
diamonds %>% select(y) %>% filter(y<15) %>% with(hist(y))
diamonds %>% select(y) %>% filter(y<15) %>% hist(y)
?with
diamonds %>% select(z) %>% filter(z<10) %>% with(hist(z))
diamonds %>% select(x) %>% %>% with(hist(x))
diamonds %>% select(x) %>% with(hist(x))
diamonds %>% select(price) %>% with(hist(price))
diamonds %>% select(x) %>% with(hist(x))
diamonds %>% select(y) %>% filter(y<15) %>% with(hist(y))
diamonds %>% select(z) %>% filter(z<10) %>% with(hist(z))
diamonds %>% select(x) %>% with(shapiro.test(x))
diamonds %>% select(x) %>% with(ks.test(x))
# Bibliotecas necessarias
library(plotrix)
library(plyr)
library(car)
library(mice)
library(xtable)
setwd("/media/rodney/Arquivos/Doutorado/PED/PEDme731/AM_S2_2020/Programas/AM_S2_2020")
diamonds %>% select(x) %>% with(ks.test(scale(x),"pnorm",0,1))
qqPlot(scale(diamonds$x),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",
xlab="quantis da N(0,1)",main=inames[j],
ylab="quantis da distribuição da distância",cex=1.2)
qqPlot(scale(diamonds$x),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",
xlab="quantis da N(0,1)",
ylab="quantis da distribuição da distância",cex=1.2)
diamantes <- diamonds %>% filter(y<15 & z<10)
qqPlot(scale(diamantes$x),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",
xlab="quantis da N(0,1)",
ylab="quantis da distribuição da distância",cex=1.2)
qqPlot(scale(diamantes$y),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",
xlab="quantis da N(0,1)",
ylab="quantis da distribuição da distância",cex=1.2)
qqPlot(scale(diamantes$z),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",
xlab="quantis da N(0,1)",
ylab="quantis da distribuição da distância",cex=1.2)
hist(diamantes$y)
hist(diamonds$y)
diamonds %>% select(y) %>% filter(y<10) %>% with(hist(y))
diamonds %>% select(y) %>% filter(y<10 & y>3) %>% with(hist(y))
diamonds %>% select(z) %>% filter(z<10) %>% with(hist(z))
diamonds %>% select(y) %>% filter(y<10 & y>3) %>% with(hist(y))
diamonds %>% select(z) %>% filter(z<10) %>% with(hist(z))
diamonds %>% select(z) %>% filter(z<6 & z>2) %>% with(hist(z))
diamonds %>% select(y) %>% filter(y<10 & y>3) %>% with(hist(y))
diamonds %>% select(x) %>% with(hist(x))
diamonds %>% select(x) %>% filter(x<9 & x>3) %>% with(hist(x))
diamonds %>% select(y) %>% with(hist(y))
diamonds %>% select(z) %>% filter(z<6 & z>2) %>% with(hist(z))
diamantes <- diamonds %>% filter(x<9 & x>3 & y<10 & y>3 & z<6 & z>2)
qqPlot(scale(diamantes$z),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",
xlab="quantis da N(0,1)",
ylab="quantis da distribuição da distância",cex=1.2)
diamantes <- diamonds %>% filter(cut %in% c("Good","Very Good") ) %>%
filter(x<9 & x>3 & y<10 & y>3 & z<6 & z>2)
diamonds %>% select(x) %>% with(ks.test(scale(x),"pnorm",0,1))
qqPlot(scale(diamantes$z),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",
xlab="quantis da N(0,1)",
ylab="quantis da distribuição da distância",cex=1.2)
qqPlot(scale(diamantes$x),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",
xlab="quantis da N(0,1)",
ylab="quantis da distribuição da distância",cex=1.2)
qqPlot(scale(diamantes$y),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",
xlab="quantis da N(0,1)",
ylab="quantis da distribuição da distância",cex=1.2)
car_body <- read.table("./car_body_data.dat")
head(car_body)
qqPlot(scale(car_body$V1),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",
xlab="quantis da N(0,1)",
ylab="quantis da distribuição da distância",cex=1.2)
qqPlot(scale(car_body$V2),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",
xlab="quantis da N(0,1)",
ylab="quantis da distribuição da distância",cex=1.2)
qqPlot(scale(car_body$V3),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",
xlab="quantis da N(0,1)",
ylab="quantis da distribuição da distância",cex=1.2)
qqPlot(scale(car_body$V4),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",
xlab="quantis da N(0,1)",
ylab="quantis da distribuição da distância",cex=1.2)
qqPlot(scale(car_body$V5),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",
xlab="quantis da N(0,1)",
ylab="quantis da distribuição da distância",cex=1.2)
qqPlot(scale(car_body$V6),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",
xlab="quantis da N(0,1)",
ylab="quantis da distribuição da distância",cex=1.2)
names(car_body)
i
summary(car_body)
hist(car_body$V5)
apply(car_body,2,mean)
apply(car_body,2,mean)
apply(car_body,2,sd)
apply(car_body,2,min)
apply(car_body,2,max)
par(mfrow=c(3,3))
for(i in 1:6)
{
qqPlot(scale(car_body$V6),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",
xlab="quantis da N(0,1)",main=names(car_body)[i],
ylab="quantis da distribuição da distância",cex=1.2)
}
# histrogram das variáveis
par(mfrow=c(3,3))
for(i in 1:6)
{
hist(car_body[,i],main=names(car_body)[i],cex=1.2)
}
# histrogram das variáveis
par(mfrow=c(3,2))
for(i in 1:6)
{
hist(car_body[,i],main=names(car_body)[i],cex=1.2)
}
names(car_body)[i]
for(i in 1:6)
{
hist(car_body[,i],main=paste(names(car_body)[i]),cex=1.2)
}
names(car_body)[i]
paste(names(car_body)[i])
for(i in 1:6)
{
hist(car_body[,i],main=paste(names(car_body)[i]),cex=1.2,xlab="")
}
# gráfico de quantis-quantis
par(mfrow=c(3,2))
# gráfico de quantis-quantis
par(mfrow=c(3,2))
for(i in 1:6)
{
qqPlot(scale(car_body[,i]),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",
xlab="quantis da N(0,1)",main=names(car_body)[i],
ylab="quantis da distribuição da distância",cex=1.2)
}
?mahalanobis
# estimando o vetor de médias e a matriz de covariâncias
vmu <- apply(car_body,2,mean)
vm
vmu
s2 <- cov(car_body)
s2
T2
vmu0 = rep(0,6)
mS2 <- cov(car_body)
T2 = n*t(vmu - vmu0)%*%solve(mS2)%*%(vmu - vmu0)
vmu0 = rep(0,6)
T2 = n*t(vmu - vmu0)%*%solve(mS2)%*%(vmu - vmu0)
vmu - vmu0
t(vmu - vmu0)
# estimando o vetor de médias e a matriz de covariâncias
vmu <- c(apply(car_body,2,mean))
vmu
vmu0 = rep(0,6)
vmu0
t(vmu - vmu0)
t(vmu - vmu0)%*%solve(mS2)
(vmu - vmu0)
t(vmu - vmu0)%*%solve(mS2)%*%(vmu - vmu0)
T2 = n*t(vmu - vmu0)%*%solve(mS2)%*%(vmu - vmu0)
n
#  levando em conta que a matriz de covariâncias é desconhecida,
#  a estatística de teste é calculada a seguir
n = dim(car_body)[1]
n
T2 = n*t(vmu - vmu0)%*%solve(mS2)%*%(vmu - vmu0)
T2
p
p = 6
# usando a relação entre T2 e a distribuição F temos que
Fstat = (n-p)*T2/( (n-1)*p )
Fstat
pf(0.05,df1 = p, df2 = n-p, lower.tail = TRUE)
pf(0.95,df1 = p, df2 = n-p, lower.tail = TRUE)
qf(0.95,df1 = p, df2 = n-p, lower.tail = TRUE)
qf(0.05,df1 = p, df2 = n-p, lower.tail = TRUE)
?qf
qf(0.95,df1 = p, df2 = n-p, lower.tail = TRUE)
# usando a relação entre T2 e a distribuição F temos que
Fstat = (n-p)*T2/( (n-1)*p ); Fstat
qf(0.95,df1 = p, df2 = n-p, lower.tail = TRUE)
# nesse caso, podemos usar a seguinte matriz de contraste
mR = matrix(c(0,0,1,-1,0,0,
0,0,0,-1,0,1),2,6)
mR
# nesse caso, podemos usar a seguinte matriz de contraste
mR = matrix(c(0,0,1,-1,0,0,
0,0,0,-1,0,1),2,6,byrow = TRUE)
mR
# nesse caso, podemos usar a seguinte matriz de contraste
mR = matrix(c(0,0,1,-1,0,0,
0,0,0,-1,0,1,
0,0,0,0,1,0),2,6,byrow = TRUE); mR
# nesse caso, podemos usar a seguinte matriz de contraste
mR = matrix(c(0,0,1,-1,0,0,
0,0,0,-1,0,1,
0,0,0,0,1,0),3,6,byrow = TRUE); mR
rank(mR)
# podemos usar a estatística de teste dada em aula
vY = mR%*%vmu
Fstat = ((n-3)*n/( (n-1)*3 ))*
t(vY - vb)%*%solve(mR%*%mS2%*%t(mR))%*%(vY - vb); Fstat
vb = c(0,0,3/4)  # vetor com as restrições
# nesse caso, podemos usar a seguinte matriz de contraste
mR = matrix(c(0,0,1,-1,0,0,
0,0,0,-1,0,1,
0,0,0,0,1,0),3,6,byrow = TRUE); mR
vb = c(0,0,3/4)  # vetor com as restrições
# podemos usar a estatística de teste dada em aula
vY = mR%*%vmu
Fstat = ((n-3)*n/( (n-1)*3 ))*
t(vY - vb)%*%solve(mR%*%mS2%*%t(mR))%*%(vY - vb); Fstat
qf(0.95,df1 = 3, df2 = n-3, lower.tail = TRUE)
?qqPlot
